{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import adjacency\n",
    "import os\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/h6x/git_projects/data_processing/processed_data/SVI/SVI2018_MIN_MAX_SCALED_MISSING_REMOVED_GNN_ID'\n",
    "VARIABLE = 'EP_POV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state= 'AL'\n",
    "svi_od_path = os.path.join(DATA_PATH, state, state + '.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_od = gpd.read_file(svi_od_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ST_ABBR</th>\n",
       "      <th>STCNTY</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>AREA_SQMI</th>\n",
       "      <th>E_TOTPOP</th>\n",
       "      <th>M_TOTPOP</th>\n",
       "      <th>...</th>\n",
       "      <th>E_UNINSUR</th>\n",
       "      <th>M_UNINSUR</th>\n",
       "      <th>EP_UNINSUR</th>\n",
       "      <th>MP_UNINSUR</th>\n",
       "      <th>E_DAYPOP</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>gnn_id</th>\n",
       "      <th>percentile</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001020100</td>\n",
       "      <td>Census Tract 201, Autauga County, Alabama</td>\n",
       "      <td>3.790677</td>\n",
       "      <td>1923</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>79</td>\n",
       "      <td>0.093</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1018</td>\n",
       "      <td>0.150082</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-86.50916 32.47344, -86.50620 32.475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001020300</td>\n",
       "      <td>Census Tract 203, Autauga County, Alabama</td>\n",
       "      <td>2.065365</td>\n",
       "      <td>3476</td>\n",
       "      <td>433</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>81</td>\n",
       "      <td>0.034</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1836</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>610</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-86.47087 32.47573, -86.46964 32.478...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001020400</td>\n",
       "      <td>Census Tract 204, Autauga County, Alabama</td>\n",
       "      <td>2.464982</td>\n",
       "      <td>3831</td>\n",
       "      <td>337</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>100</td>\n",
       "      <td>0.028</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.114106</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>611</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-86.45394 32.49318, -86.44742 32.493...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001020500</td>\n",
       "      <td>Census Tract 205, Autauga County, Alabama</td>\n",
       "      <td>4.404987</td>\n",
       "      <td>9883</td>\n",
       "      <td>726</td>\n",
       "      <td>...</td>\n",
       "      <td>398</td>\n",
       "      <td>223</td>\n",
       "      <td>0.042</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8342</td>\n",
       "      <td>0.159359</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>612</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-86.43816 32.45069, -86.43773 32.451...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>AL</td>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>01001020801</td>\n",
       "      <td>Census Tract 208.01, Autauga County, Alabama</td>\n",
       "      <td>47.981925</td>\n",
       "      <td>2826</td>\n",
       "      <td>324</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>84</td>\n",
       "      <td>0.051</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1331</td>\n",
       "      <td>0.587644</td>\n",
       "      <td>0.012689</td>\n",
       "      <td>613</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-86.59535 32.38272, -86.59454 32.383...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST    STATE ST_ABBR STCNTY   COUNTY         FIPS  \\\n",
       "0  01  ALABAMA      AL  01001  Autauga  01001020100   \n",
       "1  01  ALABAMA      AL  01001  Autauga  01001020300   \n",
       "2  01  ALABAMA      AL  01001  Autauga  01001020400   \n",
       "3  01  ALABAMA      AL  01001  Autauga  01001020500   \n",
       "4  01  ALABAMA      AL  01001  Autauga  01001020801   \n",
       "\n",
       "                                       LOCATION  AREA_SQMI  E_TOTPOP  \\\n",
       "0     Census Tract 201, Autauga County, Alabama   3.790677      1923   \n",
       "1     Census Tract 203, Autauga County, Alabama   2.065365      3476   \n",
       "2     Census Tract 204, Autauga County, Alabama   2.464982      3831   \n",
       "3     Census Tract 205, Autauga County, Alabama   4.404987      9883   \n",
       "4  Census Tract 208.01, Autauga County, Alabama  47.981925      2826   \n",
       "\n",
       "   M_TOTPOP  ...  E_UNINSUR  M_UNINSUR  EP_UNINSUR  MP_UNINSUR  E_DAYPOP  \\\n",
       "0       253  ...        178         79       0.093         4.1      1018   \n",
       "1       433  ...        119         81       0.034         2.2      1836   \n",
       "2       337  ...        108        100       0.028         2.6      1951   \n",
       "3       726  ...        398        223       0.042         2.4      8342   \n",
       "4       324  ...        144         84       0.051         2.9      1331   \n",
       "\n",
       "   Shape_Leng  Shape_Area  gnn_id  percentile  \\\n",
       "0    0.150082    0.000948     609           2   \n",
       "1    0.100175    0.000516     610           2   \n",
       "2    0.114106    0.000609     611           2   \n",
       "3    0.159359    0.001099     612           2   \n",
       "4    0.587644    0.012689     613           2   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-86.50916 32.47344, -86.50620 32.475...  \n",
       "1  POLYGON ((-86.47087 32.47573, -86.46964 32.478...  \n",
       "2  POLYGON ((-86.45394 32.49318, -86.44742 32.493...  \n",
       "3  POLYGON ((-86.43816 32.45069, -86.43773 32.451...  \n",
       "4  POLYGON ((-86.59535 32.38272, -86.59454 32.383...  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svi_od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01001', '01003', '01005', '01007', '01009', '01013', '01015',\n",
       "       '01017', '01021', '01025', '01027', '01031', '01033', '01035',\n",
       "       '01039', '01043', '01045', '01047', '01049', '01051', '01053',\n",
       "       '01055', '01057', '01059', '01063', '01067', '01069', '01071',\n",
       "       '01073', '01075', '01077', '01079', '01081', '01083', '01087',\n",
       "       '01089', '01091', '01093', '01095', '01097', '01099', '01101',\n",
       "       '01103', '01107', '01109', '01111', '01113', '01115', '01117',\n",
       "       '01121', '01123', '01125', '01127', '01133', '01011', '01019',\n",
       "       '01023', '01029', '01037', '01041', '01061', '01065', '01085',\n",
       "       '01105', '01119', '01129', '01131'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svi_od['STCNTY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 129)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svi_od.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = adjacency.process_county(state=state, county_stcnty='01043', variable=VARIABLE,data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplices = graph_data['simplices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_df = graph_data['dataframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(simplices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45922\n",
      "45923\n",
      "[45922, 45923]\n",
      "[45923, 45922]\n"
     ]
    }
   ],
   "source": [
    "p=0\n",
    "\n",
    "edges = []\n",
    "for i in range(len(simplices)):\n",
    "    # print(simplices[i]\n",
    "    \n",
    "    if len(simplices[i])==2:\n",
    "\n",
    "        edge = []\n",
    "        \n",
    "        for j in range(len(simplices[i])):\n",
    "\n",
    "            # print(simplices[i][j])\n",
    "            # print(variable_df[variable_df['simplices']==i])\n",
    "\n",
    "            print(variable_df[variable_df['sortedID']==simplices[i][j]]['gnn_id'].values[0])\n",
    "            edge.append(variable_df[variable_df['sortedID']==simplices[i][j]]['gnn_id'].values[0])\n",
    "\n",
    "        print(edge)\n",
    "        # flip the edge\n",
    "        print(edge[::-1])\n",
    "\n",
    "        edges.append(edge)\n",
    "\n",
    "    # print(variable_df[variable_df['simplices']==i])\n",
    "\n",
    "    # p=p+1\n",
    "    # if p==4:\n",
    "\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.3.0+cu121\n",
      "Cuda available: True\n",
      "Torch geometric version: 2.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "import numpy as np \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "\n",
    "# import deepchem as dc\n",
    "# from rdkit import Chem \n",
    "\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
    "print(f\"Torch geometric version: {torch_geometric.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpioidDataset(Dataset):\n",
    "    def __init__(self, root,filename,test=False, transform=None, pre_transform=None, pre_filter=None):\n",
    "        \"\"\"\n",
    "        root = Where the dataset should be stored. This folder is split\n",
    "        into raw_dir (downloaded dataset) and processed_dir (processed data). \n",
    "        \"\"\"\n",
    "        self.test = test\n",
    "        self.filename = filename\n",
    "        super(OpioidDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        \"\"\" If this file exists in raw_dir, the download is not triggered.\n",
    "            (The download func. is not implemented here)  \n",
    "        \"\"\"\n",
    "        return self.filename\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        \"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\n",
    "        self.data = pd.read_csv(self.raw_paths[0]).reset_index()\n",
    "\n",
    "        if self.test:\n",
    "            return [f'data_test_{i}.pt' for i in list(self.data.index)]\n",
    "        else:\n",
    "            return [f'data_{i}.pt' for i in list(self.data.index)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        pass \n",
    "        # idx = 0\n",
    "        # for raw_path in self.raw_paths:\n",
    "        #     # Read data from `raw_path`.\n",
    "        #     data = Data(...)\n",
    "\n",
    "        #     if self.pre_filter is not None and not self.pre_filter(data):\n",
    "        #         continue\n",
    "\n",
    "        #     if self.pre_transform is not None:\n",
    "        #         data = self.pre_transform(data)\n",
    "\n",
    "        #     torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        #     idx += 1\n",
    "\n",
    "    def _get_label(self, label):\n",
    "        label = np.asarray([label])\n",
    "        return torch.tensor(label, dtype=torch.int64)\n",
    "\n",
    "    def len(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def get(self, idx):\n",
    "        \"\"\" - Equivalent to __getitem__ in pytorch\n",
    "            - Is not needed for PyG's InMemoryDataset\n",
    "        \"\"\"\n",
    "        if self.test:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_test_{idx}.pt'))\n",
    "        else:\n",
    "            data = torch.load(os.path.join(self.processed_dir, \n",
    "                                 f'data_{idx}.pt'))        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us_svi = gpd.read_file('/home/h6x/git_projects/data_processing/raw_data/svi/2018/SVI2018_US_tract_dropped_missing.gdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make us_svi['STCNTY'].unique() a list\n",
    "county_names = us_svi['STCNTY'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add '.npy' to each element in the list\n",
    "county_names = [name + '.npy' for name in county_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3141"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(county_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01001.npy'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "county_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_name = \"/home/h6x/git_projects/gnn/model_1/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mOpioidDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcounty_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 9\u001b[0m, in \u001b[0;36mOpioidDataset.__init__\u001b[0;34m(self, root, filename, test, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest \u001b[38;5;241m=\u001b[39m test\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOpioidDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch_geometric/data/dataset.py:115\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch_geometric/data/dataset.py:253\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m osp\u001b[38;5;241m.\u001b[39mexists(f) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(f) \u001b[38;5;241m!=\u001b[39m _repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_filter):\n\u001b[1;32m    247\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `pre_filter` argument differs from the one used in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe pre-processed version of this dataset. If you want to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake use of another pre-fitering technique, pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`force_reload=True` explicitly to reload the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_reload \u001b[38;5;129;01mand\u001b[39;00m files_exist(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_paths\u001b[49m):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytest\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/torch_geometric/data/dataset.py:212\u001b[0m, in \u001b[0;36mDataset.processed_paths\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessed_paths\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"The absolute filepaths that must be present in order to skip\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    processing.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_file_names\u001b[49m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# Prevent a common source of error in which `file_names` are not\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# defined as a property.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(files, Callable):\n",
      "Cell \u001b[0;32mIn[38], line 21\u001b[0m, in \u001b[0;36mOpioidDataset.processed_file_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocessed_file_names\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" If these files are found in raw_dir, processing is skipped\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mindex)]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_env/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x93 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "OpioidDataset(root_name, filename=county_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
